{"version":3,"sources":["src/index.js"],"names":["Crawler","constructor","options","_options","Object","assign","maxRequest","skipStrictDuplicates","sameOrigin","maxDepth","parallel","hostdomain","linksToCrawl","Map","linksCrawled","_actions","preRequest","x","onSuccess","evaluatePage","init","url","Error","link","URL","origin","error","sanitizedUrl","shouldRequest","linksCollected","scrapePage","length","set","addToQueue","size","crawl","collectAnchors","$","actualHref","protocol","map","i","e","href","attr","startsWith","filter","get","console","Set","skipRequest","allowOrigin","checkSameOrigin","linkAlreadyCollected","Function","message","evaluate","result","urlCollected","depth","linkEdited","Promise","resolve","reject","canceled","currentCrawlers","pullQueue","checkMaxRequest","currentLink","keys","next","value","currentDepth","delete","pull","then","catch","scrapeSucceed","urlScraped","has","retriedFetch","fetch","textBuffer","textResponse","text","cheerio","load","all","launch","startCrawlingAt","Date","crawler","finishCrawlingAt","linksVisited","module","exports"],"mappings":";;AAAA;;AACA;;AACA;;;;AAEA,MAAMA,OAAN,CAAc;AACZC,EAAAA,WAAW,CAACC,OAAO,GAAG,EAAX,EAAe;AACxB,SAAKC,QAAL,GAAgBC,MAAM,CAACC,MAAP,CACd,EADc,EAEd;AACEC,MAAAA,UAAU,EAAE,CAAC,CADf;AAEEC,MAAAA,oBAAoB,EAAE,IAFxB;AAGEC,MAAAA,UAAU,EAAE,IAHd;AAIEC,MAAAA,QAAQ,EAAE,CAJZ;AAKEC,MAAAA,QAAQ,EAAE;AALZ,KAFc,EASdR,OATc,CAAhB;AAWA,SAAKS,UAAL,GAAkB,EAAlB;AACA,SAAKC,YAAL,GAAoB,IAAIC,GAAJ,EAApB;AACA,SAAKC,YAAL,GAAoB,IAAID,GAAJ,EAApB;AACA,SAAKE,QAAL,GAAgB;AACdC,MAAAA,UAAU,EAAE,KAAKb,QAAL,CAAca,UAAd,KAA6BC,CAAC,IAAIA,CAAlC,CADE;AAEdC,MAAAA,SAAS,EAAE,KAAKf,QAAL,CAAce,SAAd,IAA2B,IAFxB;AAGdC,MAAAA,YAAY,EAAE,KAAKhB,QAAL,CAAcgB,YAAd,IAA8B;AAH9B,KAAhB;AAKD;AAED;;;;;;;AAKA,QAAMC,IAAN,GAAa;AACX,QAAI;AACF,UAAI,CAAC,kBAAM,KAAKjB,QAAL,CAAckB,GAApB,CAAL,EAA+B,MAAM,IAAIC,KAAJ,EAAN;AAC/B,YAAMC,IAAI,GAAG,IAAIC,GAAJ,CAAQ,KAAKrB,QAAL,CAAckB,GAAtB,CAAb;AACA,WAAKV,UAAL,GAAkBY,IAAI,CAACE,MAAvB;AACA,UAAI,CAAC,KAAKd,UAAV,EAAsB,MAAM,IAAIW,KAAJ,EAAN;AACvB,KALD,CAKE,OAAOI,KAAP,EAAc;AACd,YAAM,IAAIJ,KAAJ,CAAU,2BAAV,CAAN;AACD;;AAED,UAAMK,YAAY,GAAG,MAAM,KAAKC,aAAL,CAAmB,KAAKzB,QAAL,CAAckB,GAAjC,CAA3B;AACA,QAAI,CAACM,YAAL,EAAmB;AAEnB,UAAM;AAAEE,MAAAA;AAAF,QAAqB,MAAM,KAAKC,UAAL,CAAgBH,YAAhB,CAAjC;AACA,QAAIE,cAAc,CAACE,MAAf,KAA0B,CAA9B,EAAiC;AACjC,SAAKjB,YAAL,CAAkBkB,GAAlB,CAAsBL,YAAtB;AACA,UAAM,KAAKM,UAAL,CAAgBJ,cAAhB,EAAgC,CAAhC,CAAN;AACA,QAAI,KAAKjB,YAAL,CAAkBsB,IAAlB,GAAyB,CAA7B,EAAgC,MAAM,KAAKC,KAAL,EAAN;AACjC;AAED;;;;;;;;AAMAC,EAAAA,cAAc,CAACC,CAAD,EAAIC,UAAJ,EAAgB;AAC5B,QAAIT,cAAc,GAAG,EAArB;;AACA,QAAI;AACF,YAAM;AAAEJ,QAAAA,MAAF;AAAUc,QAAAA;AAAV,UAAuB,IAAIf,GAAJ,CAAQc,UAAR,CAA7B;AACAT,MAAAA,cAAc,GAAGQ,CAAC,CAAC,GAAD,CAAD,CACdG,GADc,CACV,CAACC,CAAD,EAAIC,CAAJ,KAAU;AACb,cAAMC,IAAI,GAAGN,CAAC,CAACK,CAAD,CAAD,CAAKE,IAAL,CAAU,MAAV,KAAqB,EAAlC;AACA,YAAID,IAAI,CAACE,UAAL,CAAgB,IAAhB,CAAJ,EAA2B,OAAON,QAAQ,GAAGI,IAAlB,CAA3B,KACK,IAAIA,IAAI,CAACE,UAAL,CAAgB,GAAhB,CAAJ,EAA0B,OAAOpB,MAAM,GAAGkB,IAAhB,CAA1B,KACA,OAAOA,IAAP;AACN,OANc,EAMZ;AANY,OAOdG,MAPc,CAOP,CAACL,CAAD,EAAIE,IAAJ,KAAa,kBAAMA,IAAN,CAPN,EAOmB;AAPnB,OAQdI,GARc,EAAjB,CAFE,CAUO;AACV,KAXD,CAWE,OAAOrB,KAAP,EAAc;AACdsB,MAAAA,OAAO,CAACtB,KAAR,CAAe,2CAA0CY,UAAW,EAApE;AACAU,MAAAA,OAAO,CAACtB,KAAR,CAAcA,KAAd;AACD;;AAED,WAAO,CAAC,GAAG,IAAIuB,GAAJ,CAAQpB,cAAR,CAAJ,CAAP,CAlB4B,CAkBQ;AACrC;AAED;;;;;;;AAKA,QAAMqB,WAAN,CAAkB3B,IAAlB,EAAwB;AACtB,UAAM4B,WAAW,GAAG,KAAKC,eAAL,CAAqB7B,IAArB,CAApB;AACA,QAAI,CAAC4B,WAAL,EAAkB,OAAO,IAAP;AAClB,QAAI,KAAKhD,QAAL,CAAcI,oBAAd,IAAsC,KAAK8C,oBAAL,CAA0B9B,IAA1B,CAA1C,EAA2E,OAAO,IAAP;AAC3E,UAAMK,aAAa,GAAG,MAAM,KAAKA,aAAL,CAAmBL,IAAnB,CAA5B;AACA,WAAO,CAACK,aAAR;AACD;AAED;;;;;;;AAKA,QAAMA,aAAN,CAAoBL,IAApB,EAA0B;AACxB,QAAI,KAAKR,QAAL,CAAcC,UAAd,YAAoCsC,QAAxC,EAAkD;AAChD,UAAI;AACF,cAAMtC,UAAU,GAAG,MAAM,KAAKD,QAAL,CAAcC,UAAd,CAAyBO,IAAzB,CAAzB;AACA,YAAI,OAAOP,UAAP,KAAsB,QAAtB,IAAkCA,UAAU,KAAK,KAArD,EAA4D,OAAOA,UAAP;AAC5D,cAAM,IAAIM,KAAJ,CAAU,mDAAV,CAAN;AACD,OAJD,CAIE,OAAOI,KAAP,EAAc;AACdsB,QAAAA,OAAO,CAACtB,KAAR,CAAc,2CAAd;AACAsB,QAAAA,OAAO,CAACtB,KAAR,CAAcA,KAAK,CAAC6B,OAApB;AACD;AACF;;AACD,WAAOhC,IAAP;AACD;AAED;;;;;;;AAKA6B,EAAAA,eAAe,CAAC/B,GAAD,EAAM;AACnB,QAAI,KAAKlB,QAAL,CAAcK,UAAlB,EAA8B,OAAO,IAAIgB,GAAJ,CAAQH,GAAR,EAAaI,MAAb,KAAwB,KAAKd,UAApC;AAC9B,WAAO,IAAP;AACD;AAED;;;;;;;AAKA,QAAM6C,QAAN,CAAenB,CAAf,EAAkB;AAChB,QAAIoB,MAAM,GAAG,IAAb;;AACA,QAAI,KAAK1C,QAAL,CAAcI,YAAd,IAA8B,KAAKJ,QAAL,CAAcI,YAAd,YAAsCmC,QAAxE,EAAkF;AAChFG,MAAAA,MAAM,GAAG,MAAM,KAAK1C,QAAL,CAAcI,YAAd,CAA2BkB,CAA3B,CAAf;AACD;;AACD,WAAOoB,MAAP;AACD;AAED;;;;;;;;AAMA,QAAMxB,UAAN,CAAiByB,YAAjB,EAA+BC,KAAK,GAAG,CAAvC,EAA0C;AACxC,SAAK,MAAMtC,GAAX,IAAkBqC,YAAlB,EAAgC;AAC9B,UAAIC,KAAK,IAAI,KAAKxD,QAAL,CAAcM,QAAvB,IAAmC,EAAE,MAAM,KAAKyC,WAAL,CAAiB7B,GAAjB,CAAR,CAAvC,EAAuE;AACrE,cAAMuC,UAAU,GAAG,MAAM,KAAKhC,aAAL,CAAmBP,GAAnB,CAAzB;AACA,aAAKT,YAAL,CAAkBoB,GAAlB,CAAsB4B,UAAtB,EAAkCD,KAAlC;AACD;AACF;AACF;AAED;;;;;;AAIAxB,EAAAA,KAAK,GAAG;AACN,WAAO,IAAI0B,OAAJ,CAAY,CAACC,OAAD,EAAUC,MAAV,KAAqB;AACtC,UAAIC,QAAQ,GAAG,KAAf;AACA,UAAIC,eAAe,GAAG,CAAtB;;AACA,YAAMC,SAAS,GAAG,MAAM;AACtB,YAAIF,QAAJ,EAAc;;AACd,eAAOC,eAAe,GAAG,KAAK9D,QAAL,CAAcO,QAAhC,IAA4C,KAAKE,YAAL,CAAkBsB,IAAlB,GAAyB,CAA5E,EAA+E;AAC7E8B,UAAAA,QAAQ,GAAG,CAAC,KAAKG,eAAL,EAAZ;;AACA,cAAIH,QAAJ,EAAc;AACZC,YAAAA,eAAe,KAAK,CAApB,IAAyBH,OAAO,EAAhC;AACA;AACD;;AACDG,UAAAA,eAAe;AACf,gBAAMG,WAAW,GAAG,KAAKxD,YAAL,CAAkByD,IAAlB,GAAyBC,IAAzB,GAAgCC,KAApD;AACA,gBAAMC,YAAY,GAAG,KAAK5D,YAAL,CAAkBmC,GAAlB,CAAsBqB,WAAtB,CAArB;AACA,eAAKxD,YAAL,CAAkB6D,MAAlB,CAAyBL,WAAzB;AACA,eAAKtD,YAAL,CAAkBkB,GAAlB,CAAsBoC,WAAtB;AACA,eAAKM,IAAL,CAAUN,WAAV,EAAuBI,YAAvB,EACGG,IADH,CACQ,MAAM;AACVV,YAAAA,eAAe;AACf,gBAAIA,eAAe,KAAK,CAApB,KAA0B,KAAKrD,YAAL,CAAkBsB,IAAlB,KAA2B,CAA3B,IAAgC8B,QAA1D,CAAJ,EAAyEF,OAAO,GAAhF,KACKI,SAAS;AACf,WALH,EAMGU,KANH,CAMSlD,KAAK,IAAI;AACdsC,YAAAA,QAAQ,GAAG,IAAX;AACAD,YAAAA,MAAM,CAACrC,KAAD,CAAN;AACD,WATH;AAUD;AACF,OAxBD;;AAyBAwC,MAAAA,SAAS;AACV,KA7BM,CAAP;AA8BD;AAED;;;;;;;;AAMA,QAAMQ,IAAN,CAAWnD,IAAX,EAAiBoC,KAAjB,EAAwB;AACtB,QAAI;AACF,YAAM;AAAEF,QAAAA,MAAF;AAAU5B,QAAAA;AAAV,UAA6B,MAAM,KAAKC,UAAL,CAAgBP,IAAhB,CAAzC;AACA,YAAM,KAAKsD,aAAL,CAAmB;AAAEC,QAAAA,UAAU,EAAEvD,IAAd;AAAoBkC,QAAAA;AAApB,OAAnB,CAAN;AACA,YAAM,KAAKxB,UAAL,CAAgBJ,cAAhB,EAAgC8B,KAAK,GAAG,CAAxC,CAAN;AACD,KAJD,CAIE,OAAOjC,KAAP,EAAc;AACdsB,MAAAA,OAAO,CAACtB,KAAR,CAAcA,KAAd;AACD;AACF;AAED;;;;;;;AAKA2B,EAAAA,oBAAoB,CAAChC,GAAD,EAAM;AACxB,WAAO,KAAKP,YAAL,CAAkBiE,GAAlB,CAAsB1D,GAAtB,KAA8B,KAAKT,YAAL,CAAkBmE,GAAlB,CAAsB1D,GAAtB,CAArC;AACD;AAED;;;;;;AAIA8C,EAAAA,eAAe,GAAG;AAChB,QAAI,KAAKhE,QAAL,CAAcG,UAAd,KAA6B,CAAC,CAAlC,EAAqC,OAAO,IAAP;AACrC,WAAO,KAAKQ,YAAL,CAAkBoB,IAAlB,GAAyB,KAAK/B,QAAL,CAAcG,UAA9C;AACD;AAED;;;;;;;AAKA,QAAMuE,aAAN,CAAoB;AAAEC,IAAAA,UAAF;AAAcrB,IAAAA;AAAd,GAApB,EAA4C;AAC1C,QAAI,KAAK1C,QAAL,CAAcG,SAAd,IAA2B,KAAKH,QAAL,CAAcG,SAAd,YAAmCoC,QAAlE,EAA4E;AAC1E,UAAI;AACF,cAAM,KAAKvC,QAAL,CAAcG,SAAd,CAAwB;AAAEuC,UAAAA,MAAF;AAAUpC,UAAAA,GAAG,EAAEyD;AAAf,SAAxB,CAAN;AACD,OAFD,CAEE,OAAOpD,KAAP,EAAc;AACdsB,QAAAA,OAAO,CAACtB,KAAR,CAAc,0CAAd;AACD;AACF;AACF;AAED;;;;;;;AAKA,QAAMI,UAAN,CAAiBT,GAAjB,EAAsB;AACpB,UAAM2D,YAAY,GAAG,yBAAaC,kBAAb,EAAoB,CAApB,CAArB;;AACA,QAAI;AACF,YAAMC,UAAU,GAAG,MAAMF,YAAY,CAAC3D,GAAD,CAArC;AACA,YAAM8D,YAAY,GAAG,MAAMD,UAAU,CAACE,IAAX,EAA3B;;AACA,YAAM/C,CAAC,GAAGgD,iBAAQC,IAAR,CAAaH,YAAb,CAAV;;AACA,YAAM,CAAC1B,MAAD,EAAS5B,cAAT,IAA2B,MAAMgC,OAAO,CAAC0B,GAAR,CAAY,CAAC,KAAK/B,QAAL,CAAcnB,CAAd,CAAD,EAAmB,KAAKD,cAAL,CAAoBC,CAApB,EAAuBhB,GAAvB,CAAnB,CAAZ,CAAvC;AACA,aAAO;AAAEQ,QAAAA,cAAF;AAAkB4B,QAAAA,MAAlB;AAA0BpC,QAAAA;AAA1B,OAAP;AACD,KAND,CAME,OAAOK,KAAP,EAAc;AACdsB,MAAAA,OAAO,CAACtB,KAAR,CAAcA,KAAd;AACA,aAAO;AACLG,QAAAA,cAAc,EAAE,EADX;AAEL4B,QAAAA,MAAM,EAAE,IAFH;AAGLpC,QAAAA;AAHK,OAAP;AAKD;AACF;AAED;;;;;;;AAKA,eAAamE,MAAb,CAAoBtF,OAApB,EAA6B;AAC3B,UAAMuF,eAAe,GAAG,IAAIC,IAAJ,EAAxB;AACA,UAAMC,OAAO,GAAG,IAAI3F,OAAJ,CAAYE,OAAZ,CAAhB;AACA,UAAMyF,OAAO,CAACvE,IAAR,EAAN;AACA,UAAMwE,gBAAgB,GAAG,IAAIF,IAAJ,EAAzB;AACA,WAAO;AAAED,MAAAA,eAAF;AAAmBG,MAAAA,gBAAnB;AAAqCC,MAAAA,YAAY,EAAEF,OAAO,CAAC7E,YAAR,CAAqBoB;AAAxE,KAAP;AACD;;AAzQW;;AA4Qd4D,MAAM,CAACC,OAAP,GAAiB/F,OAAjB","sourceRoot":"..","sourcesContent":["import { retryRequest, isUrl } from './utils'\nimport fetch from 'node-fetch'\nimport cheerio from 'cheerio'\n\nclass Crawler {\n  constructor(options = {}) {\n    this._options = Object.assign(\n      {},\n      {\n        maxRequest: -1,\n        skipStrictDuplicates: true,\n        sameOrigin: true,\n        maxDepth: 3,\n        parallel: 5\n      },\n      options\n    )\n    this.hostdomain = ''\n    this.linksToCrawl = new Map()\n    this.linksCrawled = new Map()\n    this._actions = {\n      preRequest: this._options.preRequest || (x => x),\n      onSuccess: this._options.onSuccess || null,\n      evaluatePage: this._options.evaluatePage || null\n    }\n  }\n\n  /**\n   * Init the app.\n   * Begin with the first link, and start the pulling\n   * @return {!Promise<pending>}\n   */\n  async init() {\n    try {\n      if (!isUrl(this._options.url)) throw new Error()\n      const link = new URL(this._options.url)\n      this.hostdomain = link.origin\n      if (!this.hostdomain) throw new Error()\n    } catch (error) {\n      throw new Error('URL provided is not valid')\n    }\n\n    const sanitizedUrl = await this.shouldRequest(this._options.url)\n    if (!sanitizedUrl) return\n\n    const { linksCollected } = await this.scrapePage(sanitizedUrl)\n    if (linksCollected.length === 0) return\n    this.linksCrawled.set(sanitizedUrl)\n    await this.addToQueue(linksCollected, 1)\n    if (this.linksToCrawl.size > 0) await this.crawl()\n  }\n\n  /**\n   * Get all links from the page.\n   * @param {!Cheerio} $\n   * @param {!String} actualHref\n   * @return {!Promise<Array<string>}\n   */\n  collectAnchors($, actualHref) {\n    let linksCollected = []\n    try {\n      const { origin, protocol } = new URL(actualHref)\n      linksCollected = $('a')\n        .map((i, e) => {\n          const href = $(e).attr('href') || ''\n          if (href.startsWith('//')) return protocol + href\n          else if (href.startsWith('/')) return origin + href\n          else return href\n        }) // Cheerio map method\n        .filter((i, href) => isUrl(href)) // Cheerio filter method\n        .get() // Cheerio get method to transform as an array\n    } catch (error) {\n      console.error(`Something wrong happened with this url: ${actualHref}`)\n      console.error(error)\n    }\n\n    return [...new Set(linksCollected)] // Avoid duplication\n  }\n\n  /**\n   * Check if link can be crawled (Same origin ? Already collected ? preRequest !false ?).\n   * @param {!String} link\n   * @return {!Promise<Boolean>}\n   */\n  async skipRequest(link) {\n    const allowOrigin = this.checkSameOrigin(link)\n    if (!allowOrigin) return true\n    if (this._options.skipStrictDuplicates && this.linkAlreadyCollected(link)) return true\n    const shouldRequest = await this.shouldRequest(link)\n    return !shouldRequest\n  }\n\n  /**\n   * If preRequest is provided by the user, get new link or false.\n   * @param {!String} link\n   * @return {!Promise<String || Boolean>}\n   */\n  async shouldRequest(link) {\n    if (this._actions.preRequest instanceof Function) {\n      try {\n        const preRequest = await this._actions.preRequest(link)\n        if (typeof preRequest === 'string' || preRequest === false) return preRequest\n        throw new Error('preRequest function must return a String or False')\n      } catch (error) {\n        console.error('Please try/catch your preRequest function')\n        console.error(error.message)\n      }\n    }\n    return link\n  }\n\n  /**\n   * Check if link has the same origin as the host link.\n   * @param {!String} url\n   * @return {!Boolean}\n   */\n  checkSameOrigin(url) {\n    if (this._options.sameOrigin) return new URL(url).origin === this.hostdomain\n    return true\n  }\n\n  /**\n   * If evaluatePage is provided by the user, await for it.\n   * @param {!Cheerio} $\n   * @return {!Promise<any>}\n   */\n  async evaluate($) {\n    let result = null\n    if (this._actions.evaluatePage && this._actions.evaluatePage instanceof Function) {\n      result = await this._actions.evaluatePage($)\n    }\n    return result\n  }\n\n  /**\n   * Add links collected to queue.\n   * @param {!Array<string>} urlCollected\n   * @param {!Number} depth\n   * @return {!Promise<pending>}\n   */\n  async addToQueue(urlCollected, depth = 0) {\n    for (const url of urlCollected) {\n      if (depth <= this._options.maxDepth && !(await this.skipRequest(url))) {\n        const linkEdited = await this.shouldRequest(url)\n        this.linksToCrawl.set(linkEdited, depth)\n      }\n    }\n  }\n\n  /**\n   * Crawl links from 'linksToCrawl' and wait for having 'canceled' to true.\n   * @return {!Promise<pending>}\n   */\n  crawl() {\n    return new Promise((resolve, reject) => {\n      let canceled = false\n      let currentCrawlers = 0\n      const pullQueue = () => {\n        if (canceled) return\n        while (currentCrawlers < this._options.parallel && this.linksToCrawl.size > 0) {\n          canceled = !this.checkMaxRequest()\n          if (canceled) {\n            currentCrawlers === 0 && resolve()\n            break\n          }\n          currentCrawlers++\n          const currentLink = this.linksToCrawl.keys().next().value\n          const currentDepth = this.linksToCrawl.get(currentLink)\n          this.linksToCrawl.delete(currentLink)\n          this.linksCrawled.set(currentLink)\n          this.pull(currentLink, currentDepth)\n            .then(() => {\n              currentCrawlers--\n              if (currentCrawlers === 0 && (this.linksToCrawl.size === 0 || canceled)) resolve()\n              else pullQueue()\n            })\n            .catch(error => {\n              canceled = true\n              reject(error)\n            })\n        }\n      }\n      pullQueue()\n    })\n  }\n\n  /**\n   * Pull result and links from a page and add them to the queue.\n   * @param {!String} link\n   * @param {!Number} depth\n   * @return {!Promise<pending>}\n   */\n  async pull(link, depth) {\n    try {\n      const { result, linksCollected } = await this.scrapePage(link)\n      await this.scrapeSucceed({ urlScraped: link, result })\n      await this.addToQueue(linksCollected, depth + 1)\n    } catch (error) {\n      console.error(error)\n    }\n  }\n\n  /**\n   * Know if a link will be crawled or has already been crawled.\n   * @param {!String} url\n   * @return {!Boolean}\n   */\n  linkAlreadyCollected(url) {\n    return this.linksCrawled.has(url) || this.linksToCrawl.has(url)\n  }\n\n  /**\n   * Know if we have exceeded the number of request max provided in the options.\n   * @return {!Boolean}\n   */\n  checkMaxRequest() {\n    if (this._options.maxRequest === -1) return true\n    return this.linksCrawled.size < this._options.maxRequest\n  }\n\n  /**\n   * If onSuccess action's has been provided, await for it.\n   * @param {!Object<{urlScraped: string, result: any}>}\n   * @return {!Promise<pending>}\n   */\n  async scrapeSucceed({ urlScraped, result }) {\n    if (this._actions.onSuccess && this._actions.onSuccess instanceof Function) {\n      try {\n        await this._actions.onSuccess({ result, url: urlScraped })\n      } catch (error) {\n        console.error('Please try/catch your onSuccess function')\n      }\n    }\n  }\n\n  /**\n   * Scrap a page, evaluate and get new links to visit.\n   * @param {!String} url\n   * @return {!Promise<{linksCollected: array, result: any, url: string}>}\n   */\n  async scrapePage(url) {\n    const retriedFetch = retryRequest(fetch, 2)\n    try {\n      const textBuffer = await retriedFetch(url)\n      const textResponse = await textBuffer.text()\n      const $ = cheerio.load(textResponse)\n      const [result, linksCollected] = await Promise.all([this.evaluate($), this.collectAnchors($, url)])\n      return { linksCollected, result, url }\n    } catch (error) {\n      console.error(error)\n      return {\n        linksCollected: [],\n        result: null,\n        url\n      }\n    }\n  }\n\n  /**\n   * Starting the crawl.\n   * @param {!0bject} options\n   * @return {!Promise<{startCrawlingAt: Date, finishCrawlingAt: Date, linksVisited: Number}>}\n   */\n  static async launch(options) {\n    const startCrawlingAt = new Date()\n    const crawler = new Crawler(options)\n    await crawler.init()\n    const finishCrawlingAt = new Date()\n    return { startCrawlingAt, finishCrawlingAt, linksVisited: crawler.linksCrawled.size }\n  }\n}\n\nmodule.exports = Crawler\n"],"file":"index.js"}